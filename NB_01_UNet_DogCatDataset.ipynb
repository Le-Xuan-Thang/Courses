{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1G1KXJJD26Ca1CO3lt-c6llZU4V3zSU5K",
      "authorship_tag": "ABX9TyMtRLCwgMz6NX0XhTNSwC/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lexuanthangutc/Courses/blob/main/NB_01_UNet_DogCatDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages\n",
        "\n",
        "Documentations\n",
        "- [Torchmetrics](https://lightning.ai/docs/torchmetrics/stable/)\n",
        "- [Semantic Segmentation Model Pytorch](https://smp.readthedocs.io/en/latest/)\n",
        "- [Albumentations](https://albumentations.ai/docs/examples/pytorch_classification/ )\n"
      ],
      "metadata": {
        "id": "OVE-XeLxnKxP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy5skuVtmCpK"
      },
      "outputs": [],
      "source": [
        "!pip3 install torchmetrics\n",
        "!pip3 install segmentation-models-pytorch\n",
        "!pip3 install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dog and cat segmentation dataset oxford\n",
        "!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
        "!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz"
      ],
      "metadata": {
        "id": "tZ-kKZEToENP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the file\n",
        "!tar -xf annotations.tar.gz\n",
        "!tar -xf images.tar.gz"
      ],
      "metadata": {
        "id": "bkydcr-Woh-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy  as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "from torchmetrics import Dice, JaccardIndex\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob # read and close image in folder"
      ],
      "metadata": {
        "id": "pAS4A4fAowPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Read and Understand the Data"
      ],
      "metadata": {
        "id": "OWthJSZiqvdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# image_path = \"/content/images/Abyssinian_1.jpg\"\n",
        "# image = cv2.imread(image_path)\n",
        "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "# print(image.shape)\n",
        "\n",
        "# mask_path = \"/content/annotations/trimaps/Abyssinian_1.png\"\n",
        "# mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.imshow(mask)\n",
        "# plt.show()\n",
        "# print(mask)\n",
        "# print(mask.shape)\n"
      ],
      "metadata": {
        "id": "bge6jPMWpfxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, root_dir, txt_file, transform=None):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.txt_file = txt_file\n",
        "        self.transform = transform\n",
        "        self.img_path_lst = []\n",
        "        with open(self.txt_file) as file_in:\n",
        "            for line in file_in:\n",
        "                self.img_path_lst.append(line.split(\" \")[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_lst)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.root_dir, \"images\", \"{}.jpg\".format(self.img_path_lst[idx]))\n",
        "        mask_path = os.path.join(self.root_dir, \"annotations\", \"trimaps\", \"{}.png\".format(self.img_path_lst[idx]))\n",
        "        # read image\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        #read mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # foreground -> 1\n",
        "        # background (2) -> 0\n",
        "        # Not classified (3) -> 1\n",
        "        mask[mask == 2] = 0\n",
        "        mask[mask == 3] = 1\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "\n",
        "        return image,mask\n"
      ],
      "metadata": {
        "id": "0uTCGXINrjsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainsize = 256\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(width=trainsize, height=trainsize),\n",
        "    A.HorizontalFlip(),\n",
        "    A.RandomBrightnessContrast(),\n",
        "    A.Blur(),\n",
        "    A.Sharpen(),\n",
        "    A.RGBShift(),\n",
        "    A.Cutout(),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(width=trainsize, height=trainsize),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "])"
      ],
      "metadata": {
        "id": "7HxLgiqquWB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DogCatDataset(\"/content\", \"/content/annotations/trainval.txt\", transform = train_transform)\n",
        "test_dataset = DogCatDataset(\"/content\", \"/content/annotations/test.txt\", transform = test_transform)\n",
        "# image,mask = train_dataset.__getitem__(10)\n",
        "# print(image.shape, mask.shape)\n",
        "# print(mask.unique())"
      ],
      "metadata": {
        "id": "KNuo6tkLumFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UnNomarlize"
      ],
      "metadata": {
        "id": "PEMiHjpF_bR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_np(tensor):\n",
        "    # Make sure the tensor is on the CPU and convert to NumPy\n",
        "    return tensor.detach().cpu().numpy()\n",
        "\n",
        "def np_to_tensor(array):\n",
        "    # Convert a NumPy array back to PyTorch tensor\n",
        "    return torch.tensor(array).float()\n",
        "\n",
        "def inverse_norm(image):\n",
        "    # Define the inverse transformation using Albumentations\n",
        "    invTrans = A.Compose([\n",
        "        A.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225], max_pixel_value=1.0),\n",
        "        A.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.], max_pixel_value=1.0),\n",
        "    ])\n",
        "\n",
        "    # Example usage:\n",
        "    # Assuming 'tensor_image' is your normalized image tensor\n",
        "    tensor_image_np = tensor_to_np(image)  # Convert tensor to numpy array\n",
        "    tensor_image_np = np.transpose(tensor_image_np, (1, 2, 0))  # CHW to HWC for Albumentations\n",
        "\n",
        "    # Apply the inverse transformation\n",
        "    inv_img_np = invTrans(image=tensor_image_np)['image']\n",
        "    inv_img_np = np.transpose(inv_img_np, (2, 0, 1))  # HWC back to CHW for PyTorch\n",
        "\n",
        "    # Convert back to tensor\n",
        "    inv_img_tensor = np_to_tensor(inv_img_np)\n",
        "    return inv_img_tensor\n",
        "# inv_img_tensor = inverse_norm(image)"
      ],
      "metadata": {
        "id": "esYOIhAL6DHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.subplot(1,2,1)\n",
        "# plt.imshow(inv_img_tensor.permute(1,2,0))\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.imshow(mask)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "kPVx334R4eTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Create model"
      ],
      "metadata": {
        "id": "qKQ373x0_04X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,3,1,1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3,1,1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.downsample = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2,mode='bilinear')\n",
        "        self.block_down1 = unet_block(3,64)\n",
        "        self.block_down2 = unet_block(64, 128)\n",
        "        self.block_down3 = unet_block(128, 256)\n",
        "        self.block_down4 = unet_block(256, 512)\n",
        "\n",
        "        self.block_neck = unet_block(512,1024)\n",
        "\n",
        "        self.block_up1 = unet_block(1024+512, 512)\n",
        "        self.block_up2 = unet_block(256+512, 256)\n",
        "        self.block_up3 = unet_block(128+256, 128)\n",
        "        self.block_up4 = unet_block(64+128, 64)\n",
        "\n",
        "        self.conv_cls = nn.Conv2d(64, self.num_classes, 1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1 = self.block_down1(x)\n",
        "        x = self.downsample(x1)\n",
        "        x2 = self.block_down2(x)\n",
        "        x = self.downsample(x2)\n",
        "        x3 = self.block_down3(x)\n",
        "        x = self.downsample(x3)\n",
        "        x4 = self.block_down4(x)\n",
        "        x = self.downsample(x4)\n",
        "\n",
        "        x = self.block_neck(x)\n",
        "\n",
        "        x = torch.cat([x4,self.upsample(x)], dim = 1)\n",
        "        x = self.block_up1(x)\n",
        "        x = torch.cat([x3,self.upsample(x)], dim = 1)\n",
        "        x = self.block_up2(x)\n",
        "        x = torch.cat([x2,self.upsample(x)], dim = 1)\n",
        "        x = self.block_up3(x)\n",
        "        x = torch.cat([x1,self.upsample(x)], dim = 1)\n",
        "        x = self.block_up4(x)\n",
        "\n",
        "        x = self.conv_cls(x)\n",
        "        return x\n",
        "\n",
        "# model = UNet(1)\n",
        "# x = torch.rand(4, 3, trainsize, trainsize)\n",
        "# print(\"Input shape =\", x.shape)\n",
        "# y = model(x)\n",
        "# print(\"Out shape =\", y.shape)"
      ],
      "metadata": {
        "id": "Rx42vCLC4pwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMetric(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val=0\n",
        "        self.avg=0\n",
        "        self.sum=0\n",
        "        self.count=0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val*n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "2ksXSxeOhGVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 8\n",
        "\n",
        "n_workers = os.cpu_count()\n",
        "print(\"number of workers=\", n_workers)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = n_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = n_workers)\n",
        "\n",
        "#model\n",
        "model = UNet(1).to(device)\n",
        "\n",
        "#loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "#metrics\n",
        "dice_fn = torchmetrics.Dice(num_classes=2, average=\"macro\").to(device)\n",
        "iou_fn = torchmetrics.JaccardIndex(num_classes=2, task=\"binary\", average=\"macro\").to(device)\n",
        "acc_fn = torchmetrics.Accuracy(num_classes=4, task=\"binary\").to(device)\n",
        "\n",
        "# metric\n",
        "acc_metric = AverageMetric()\n",
        "dice_metric = AverageMetric()\n",
        "iou_metric = AverageMetric()\n",
        "train_loss_metric = AverageMetric()"
      ],
      "metadata": {
        "id": "QdO2Wn1JK8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    acc_metric.reset()\n",
        "    dice_metric.reset()\n",
        "    iou_metric.reset()\n",
        "    train_loss_metric.reset()\n",
        "\n",
        "    model.train()\n",
        "    for batch_id, (x, y) in enumerate(tqdm(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).float()\n",
        "        yhat = model(x)\n",
        "        yhat = yhat.squeeze() # B,1,H,W -> B,H,W\n",
        "\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            yhat_mask = yhat.sigmoid().round().long() # -> mask 0,1\n",
        "            # print(yhat_mask.unique(), y.unique())\n",
        "            dice_score = dice_fn(yhat_mask,y.long())\n",
        "            iou_score = iou_fn(yhat_mask, y.long())\n",
        "            accuracy = acc_fn(yhat_mask, y.long())\n",
        "\n",
        "            acc_metric.update(accuracy.item(), n)\n",
        "            dice_metric.update(dice_score.item(), n)\n",
        "            iou_metric.update(iou_score.item(), n)\n",
        "            train_loss_metric.update(loss.item(), n)\n",
        "\n",
        "    print(\"Epoch {}: train_loss = {}, accuracy = {}, iou_score = {}, dice_score = {}\".format(\n",
        "        epoch, train_loss_metric.avg, acc_metric.avg, iou_metric.avg, dice_metric.avg\n",
        "    ))"
      ],
      "metadata": {
        "id": "RIqPnkRGcDwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/model_last.pth\")"
      ],
      "metadata": {
        "id": "wdqHqfUrl8ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "test_iou_metric = AverageMetric()\n",
        "test_dice_metric = AverageMetric()\n",
        "with torch.no_grad():\n",
        "    for batch_id, (x, y) in enumerate(tqdm(test_loader), start=1):\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).float()\n",
        "        yhat = model(x)\n",
        "        yhat = yhat.squeeze() # B,1,H,W -> B,H,W\n",
        "        y = y.long()\n",
        "        yhat_mask = yhat.sigmoid().round().long() # -> mask 0,1\n",
        "        dice_score = dice_fn(yhat_mask,y)\n",
        "        iou_score = iou_fn(yhat_mask, y)\n",
        "        test_dice_metric.update(dice_score.item(), n)\n",
        "        test_iou_metric.update(iou_score.item(), n)\n",
        "\n",
        "print(\"TEST: IoU = {}, dice = {}\".format(test_iou_metric.avg, test_dice_metric.avg))"
      ],
      "metadata": {
        "id": "vMKcV7He5-ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "model.eval()\n",
        "idx = random.randint(0,100)\n",
        "with torch.no_grad():\n",
        "    x, y = test_dataset[idx]\n",
        "    print(x.shape,y.shape) # (C, H , W) - > (B, C, H, W) -> model\n",
        "    x = x.to(device).float().unsqueeze(0)\n",
        "\n",
        "    yhat = model(x).squeeze() #(1, 1, H, W) -> (H,W)\n",
        "    yhat_mask = yhat.sigmoid().round().long() # -> mask 0,1\n",
        "\n",
        "    inv_img_tensor = inverse_norm(x.squeeze())\n",
        "    # draw, x, y, yhat_mask\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(inv_img_tensor.permute(1,2,0).cpu())\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(y)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(yhat_mask.cpu())"
      ],
      "metadata": {
        "id": "w-HbnXZv7GPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8to-tMt7oa3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}